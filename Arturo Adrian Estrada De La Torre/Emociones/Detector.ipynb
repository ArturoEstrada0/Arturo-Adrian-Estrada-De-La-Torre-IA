{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00a35e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Feliz', 'Neutral', 'Sorpresa', 'Triste']\n",
      "Modelo entrenado y guardado como 'imgLBPHFace.xml'\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "# Ruta del dataset\n",
    "dataSet = 'C://Users//r2rit//IA PROYECTOS//emocionesRobo//emociones//Emociones'\n",
    "faces = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "for face in faces:\n",
    "    facePath = dataSet + '/' + face\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath + '/' + faceName, 0))\n",
    "    label += 1\n",
    "\n",
    "# Verificar si las imágenes se cargaron correctamente\n",
    "if len(facesData) == 0:\n",
    "    print(\"Error: No se encontraron imágenes en el dataset.\")\n",
    "    exit()\n",
    "\n",
    "# Crear y entrenar el reconocedor facial\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('imgLBPHFace.xml')\n",
    "print(\"Modelo entrenado y guardado como 'imgLBPHFace.xml'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac86de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### import cv2 as cv\n",
    "import os \n",
    "\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.read('emocionesv3LBPHFace.xml')\n",
    "\n",
    "cap = cv.VideoCapture(1)\n",
    "rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        frame2 = cv.resize(frame2,  (100,100), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "#         cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "        if result[1] < 2800:\n",
    "            cv.putText(frame,'{}'.format(faces[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "#         else:\n",
    "#             cv.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv.LINE_AA)\n",
    "#             cv.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2) \n",
    "    cv.imshow('frame', frame)\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364896e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cce953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized tornado.jpeg to (28, 28)\n",
      "Resized tornado1.jpg to (28, 28)\n",
      "Resized Tornado10.jpg to (28, 28)\n",
      "Resized tornado2.jpg to (28, 28)\n",
      "Resized tornado20.jpg to (28, 28)\n",
      "Resized tornado3.jpg to (28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r2rit\\AppData\\Local\\Temp\\ipykernel_17772\\2462103334.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize(size, Image.ANTIALIAS)\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'C://Users//r2rit//IA PROYECTOS//CNN//imagenesPrueba//Tornado\\\\tornado30.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC://Users//r2rit//IA PROYECTOS//CNN//imagenesPrueba//Tornado\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Call the function to resize images\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m resize_images_in_folder(folder_path)\n",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m, in \u001b[0;36mresize_images_in_folder\u001b[1;34m(folder_path, size)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Check if the file is an image\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgif\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(file_path) \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;66;03m# Resize the image\u001b[39;00m\n\u001b[0;32m     23\u001b[0m         img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize(size, Image\u001b[38;5;241m.\u001b[39mANTIALIAS)\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;66;03m# Save the resized image back to the folder (overwrites the original image)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3283\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3281\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m   3282\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m-> 3283\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'C://Users//r2rit//IA PROYECTOS//CNN//imagenesPrueba//Tornado\\\\tornado30.jpg'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resize_images_in_folder(folder_path, size=(28, 28)):\n",
    "    \"\"\"\n",
    "    Resizes all images in the given folder to the specified size.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str): The path to the folder containing images.\n",
    "        size (tuple): The desired size for the images, default is (28, 28).\n",
    "    \"\"\"\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Loop through all files\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Check if the file is an image\n",
    "        if file_path.endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):\n",
    "            with Image.open(file_path) as img:\n",
    "                # Resize the image\n",
    "                img = img.resize(size, Image.ANTIALIAS)\n",
    "                \n",
    "                # Save the resized image back to the folder (overwrites the original image)\n",
    "                img.save(file_path)\n",
    "                print(f\"Resized {file_name} to {size}\")\n",
    "    \n",
    "    print(\"All images have been resized.\")\n",
    "\n",
    "# Example usage:\n",
    "# Set the path to your folder containing images\n",
    "folder_path = 'C://Users//r2rit//IA PROYECTOS//CNN//imagenesPrueba//Tornado'\n",
    "\n",
    "# Call the function to resize images\n",
    "resize_images_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103faa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6fe18dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Feliz', 'Neutral', 'Sorpresa', 'Triste']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv  # Importa la librería OpenCV con el alias cv\n",
    "import os  # Importa el módulo os para interactuar con el sistema operativo\n",
    "\n",
    "def detectar_rostros():\n",
    "    # Directorio donde se encuentran los datos de entrenamiento\n",
    "    dataSet = \"C:\\\\Users\\\\r2rit\\\\IA PROYECTOS\\\\emocionesRobo\\\\emociones\\\\Emociones\"\n",
    "    # Lista de nombres de carpetas dentro del directorio dataSet, cada una correspondiendo a una categoría/emoción\n",
    "    faces = os.listdir(dataSet)\n",
    "    print(faces)\n",
    "\n",
    "    # Crea un objeto reconocedor de rostros utilizando el algoritmo LBPH y lo carga desde el archivo XML previamente entrenado\n",
    "    faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "    faceRecognizer.read('imgLBPHFace.xml')\n",
    "\n",
    "    # Inicia la captura de video desde la cámara\n",
    "    cap = cv.VideoCapture(1)\n",
    "    # Carga el clasificador de Haar para detectar rostros\n",
    "    rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    while True:\n",
    "        # Lee un fotograma de la cámara\n",
    "        ret, frame = cap.read()\n",
    "        # Si no se puede leer el fotograma, sale del bucle\n",
    "        if ret == False:\n",
    "            break\n",
    "        # Convierte el fotograma a escala de grises\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        # Realiza una copia del fotograma en escala de grises\n",
    "        cpGray = gray.copy()\n",
    "        # Detecta rostros en el fotograma\n",
    "        rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "        # Itera sobre cada rostro detectado\n",
    "        for(x, y, w, h) in rostros:\n",
    "            # Extrae la región de interés (ROI) que contiene el rostro\n",
    "            frame2 = cpGray[y:y+h, x:x+w]\n",
    "            # Cambia la escala del ROI a 100x100 píxeles\n",
    "            frame2 = cv.resize(frame2,  (100,100), interpolation=cv.INTER_CUBIC)\n",
    "            # Realiza la predicción del rostro utilizando el reconocedor de rostros\n",
    "            result = faceRecognizer.predict(frame2)\n",
    "            # Dibuja un texto en el fotograma con el resultado de la predicción\n",
    "            # Si la confianza de la predicción es menor a 70\n",
    "            if result[1] < 9500:\n",
    "                # Dibuja un texto en el fotograma con la categoría/emoción identificada\n",
    "                cv.putText(frame,'{}'.format(faces[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv.LINE_AA)\n",
    "                # Dibuja un rectángulo alrededor del rostro identificado\n",
    "                cv.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "            else:\n",
    "                # Si la confianza de la predicción es mayor o igual a 70, se considera como 'Desconocido'\n",
    "                cv.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv.LINE_AA)\n",
    "                # Dibuja un rectángulo alrededor del rostro no identificado\n",
    "                cv.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "        # Muestra el fotograma con los rostros detectados\n",
    "        cv.imshow('frame', frame)\n",
    "        # Espera por una tecla presionada durante 1 milisegundo\n",
    "        k = cv.waitKey(1)\n",
    "        # Si se presiona la tecla Esc (código 27 en OpenCV), sale del bucle\n",
    "        if k == 27:\n",
    "            break\n",
    "    # Libera los recursos de la cámara y cierra todas las ventanas\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "# Llama a la función detectar_rostros para iniciar el proceso de detección de rostros\n",
    "detectar_rostros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d47a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
